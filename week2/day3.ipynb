{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24bb4df2",
   "metadata": {},
   "source": [
    "Conversational AI - Chatbot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71be6203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57cfc83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key not set\n",
      "Google API Key not set\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfcf1f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI()\n",
    "MODEL = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e4d43bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6943973",
   "metadata": {},
   "source": [
    "Gradio has been upgraded! It now passes the history in the same format OpenAI expects:\n",
    "\n",
    "[\n",
    "  {\"role\": \"system\", \"content\": \"system instructions\"},\n",
    "  {\"role\": \"user\", \"content\": \"first user message\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"assistant reply\"},\n",
    "  {\"role\": \"user\", \"content\": \"next user message\"}\n",
    "]\n",
    "This means we no longer need to convert or reformat anything ourselves. We can take the history exactly as it is and send it directly to OpenAI.\n",
    "\n",
    "Here’s how we’ll handle it:\n",
    "\n",
    "We’ll define a chat(message, history) function.\n",
    "\n",
    "message is the new user input.\n",
    "\n",
    "history is the entire conversation so far, already in OpenAI’s format.\n",
    "\n",
    "Inside the function, we’ll:\n",
    "1️⃣ Add the latest message to the history.\n",
    "2️⃣ Include any required system message if needed.\n",
    "3️⃣ Send the full list of messages to OpenAI’s API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65887cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    print(\"History is:\")\n",
    "    print(history)\n",
    "    print(\"And messages is:\")\n",
    "    print(messages)\n",
    "\n",
    "    stream = openai_client.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b80d1a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7879\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7879/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History is:\n",
      "[]\n",
      "And messages is:\n",
      "[{'role': 'system', 'content': 'You are a helpful assistant'}, {'role': 'user', 'content': 'Hello Universe !!'}]\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ddbfcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant in a clothes store. You should try to gently encourage \\\n",
    "the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. \\\n",
    "For example, if the customer says 'I'm looking to buy a hat', \\\n",
    "you could reply something like, 'Wonderful - we have lots of hats - including several that are part of our sales event.'\\\n",
    "Encourage the customer to buy hats if they are unsure what to get.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29fc19bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message,history):\n",
    "    messages = [{'role': 'system', 'content': system_message}] + history + [{\"role\":\"user\",\"content\":message}]\n",
    "\n",
    "    stream = openai_client.chat.completions.create(model=MODEL,messages=messages,stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8088a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7882\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7882/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a7be524",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message += \"\\nIf the customer asks for shoes,you should respond that shoes are not on sale today, \\\n",
    "    but remind the custoer to look at hats!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3b5293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7883\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7883/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
